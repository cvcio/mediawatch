// Code generated by protoc-gen-connect-go. DO NOT EDIT.
//
// Source: mediawatch/scrape/v2/scrape.proto

package scrapev2connect

import (
	connect "connectrpc.com/connect"
	context "context"
	errors "errors"
	v2 "github.com/cvcio/mediawatch/pkg/mediawatch/scrape/v2"
	http "net/http"
	strings "strings"
)

// This is a compile-time assertion to ensure that this generated file and the connect package are
// compatible. If you get a compiler error that this constant is not defined, this code was
// generated with a version of connect newer than the one compiled into your binary. You can fix the
// problem by either regenerating this code with an older version of connect or updating the connect
// version compiled into your binary.
const _ = connect.IsAtLeastVersion0_1_0

const (
	// ScrapeServiceName is the fully-qualified name of the ScrapeService service.
	ScrapeServiceName = "mediawatch.scrape.v2.ScrapeService"
)

// These constants are the fully-qualified names of the RPCs defined in this package. They're
// exposed at runtime as Spec.Procedure and as the final two segments of the HTTP route.
//
// Note that these are different from the fully-qualified method names used by
// google.golang.org/protobuf/reflect/protoreflect. To convert from these constants to
// reflection-formatted method names, remove the leading slash and convert the remaining slash to a
// period.
const (
	// ScrapeServiceScrapeProcedure is the fully-qualified name of the ScrapeService's Scrape RPC.
	ScrapeServiceScrapeProcedure = "/mediawatch.scrape.v2.ScrapeService/Scrape"
	// ScrapeServiceSimpleScrapeProcedure is the fully-qualified name of the ScrapeService's
	// SimpleScrape RPC.
	ScrapeServiceSimpleScrapeProcedure = "/mediawatch.scrape.v2.ScrapeService/SimpleScrape"
	// ScrapeServiceReloadPassagesProcedure is the fully-qualified name of the ScrapeService's
	// ReloadPassages RPC.
	ScrapeServiceReloadPassagesProcedure = "/mediawatch.scrape.v2.ScrapeService/ReloadPassages"
)

// ScrapeServiceClient is a client for the mediawatch.scrape.v2.ScrapeService service.
type ScrapeServiceClient interface {
	// Endpoint Scrape
	Scrape(context.Context, *connect.Request[v2.ScrapeRequest]) (*connect.Response[v2.ScrapeResponse], error)
	// Endpoint SimpleScrape
	SimpleScrape(context.Context, *connect.Request[v2.SimpleScrapeRequest]) (*connect.Response[v2.ScrapeResponse], error)
	// Endpoint ReloadPassages
	ReloadPassages(context.Context, *connect.Request[v2.Empty]) (*connect.Response[v2.ReloadPassagesResponse], error)
}

// NewScrapeServiceClient constructs a client for the mediawatch.scrape.v2.ScrapeService service. By
// default, it uses the Connect protocol with the binary Protobuf Codec, asks for gzipped responses,
// and sends uncompressed requests. To use the gRPC or gRPC-Web protocols, supply the
// connect.WithGRPC() or connect.WithGRPCWeb() options.
//
// The URL supplied here should be the base URL for the Connect or gRPC server (for example,
// http://api.acme.com or https://acme.com/grpc).
func NewScrapeServiceClient(httpClient connect.HTTPClient, baseURL string, opts ...connect.ClientOption) ScrapeServiceClient {
	baseURL = strings.TrimRight(baseURL, "/")
	return &scrapeServiceClient{
		scrape: connect.NewClient[v2.ScrapeRequest, v2.ScrapeResponse](
			httpClient,
			baseURL+ScrapeServiceScrapeProcedure,
			opts...,
		),
		simpleScrape: connect.NewClient[v2.SimpleScrapeRequest, v2.ScrapeResponse](
			httpClient,
			baseURL+ScrapeServiceSimpleScrapeProcedure,
			opts...,
		),
		reloadPassages: connect.NewClient[v2.Empty, v2.ReloadPassagesResponse](
			httpClient,
			baseURL+ScrapeServiceReloadPassagesProcedure,
			opts...,
		),
	}
}

// scrapeServiceClient implements ScrapeServiceClient.
type scrapeServiceClient struct {
	scrape         *connect.Client[v2.ScrapeRequest, v2.ScrapeResponse]
	simpleScrape   *connect.Client[v2.SimpleScrapeRequest, v2.ScrapeResponse]
	reloadPassages *connect.Client[v2.Empty, v2.ReloadPassagesResponse]
}

// Scrape calls mediawatch.scrape.v2.ScrapeService.Scrape.
func (c *scrapeServiceClient) Scrape(ctx context.Context, req *connect.Request[v2.ScrapeRequest]) (*connect.Response[v2.ScrapeResponse], error) {
	return c.scrape.CallUnary(ctx, req)
}

// SimpleScrape calls mediawatch.scrape.v2.ScrapeService.SimpleScrape.
func (c *scrapeServiceClient) SimpleScrape(ctx context.Context, req *connect.Request[v2.SimpleScrapeRequest]) (*connect.Response[v2.ScrapeResponse], error) {
	return c.simpleScrape.CallUnary(ctx, req)
}

// ReloadPassages calls mediawatch.scrape.v2.ScrapeService.ReloadPassages.
func (c *scrapeServiceClient) ReloadPassages(ctx context.Context, req *connect.Request[v2.Empty]) (*connect.Response[v2.ReloadPassagesResponse], error) {
	return c.reloadPassages.CallUnary(ctx, req)
}

// ScrapeServiceHandler is an implementation of the mediawatch.scrape.v2.ScrapeService service.
type ScrapeServiceHandler interface {
	// Endpoint Scrape
	Scrape(context.Context, *connect.Request[v2.ScrapeRequest]) (*connect.Response[v2.ScrapeResponse], error)
	// Endpoint SimpleScrape
	SimpleScrape(context.Context, *connect.Request[v2.SimpleScrapeRequest]) (*connect.Response[v2.ScrapeResponse], error)
	// Endpoint ReloadPassages
	ReloadPassages(context.Context, *connect.Request[v2.Empty]) (*connect.Response[v2.ReloadPassagesResponse], error)
}

// NewScrapeServiceHandler builds an HTTP handler from the service implementation. It returns the
// path on which to mount the handler and the handler itself.
//
// By default, handlers support the Connect, gRPC, and gRPC-Web protocols with the binary Protobuf
// and JSON codecs. They also support gzip compression.
func NewScrapeServiceHandler(svc ScrapeServiceHandler, opts ...connect.HandlerOption) (string, http.Handler) {
	scrapeServiceScrapeHandler := connect.NewUnaryHandler(
		ScrapeServiceScrapeProcedure,
		svc.Scrape,
		opts...,
	)
	scrapeServiceSimpleScrapeHandler := connect.NewUnaryHandler(
		ScrapeServiceSimpleScrapeProcedure,
		svc.SimpleScrape,
		opts...,
	)
	scrapeServiceReloadPassagesHandler := connect.NewUnaryHandler(
		ScrapeServiceReloadPassagesProcedure,
		svc.ReloadPassages,
		opts...,
	)
	return "/mediawatch.scrape.v2.ScrapeService/", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		switch r.URL.Path {
		case ScrapeServiceScrapeProcedure:
			scrapeServiceScrapeHandler.ServeHTTP(w, r)
		case ScrapeServiceSimpleScrapeProcedure:
			scrapeServiceSimpleScrapeHandler.ServeHTTP(w, r)
		case ScrapeServiceReloadPassagesProcedure:
			scrapeServiceReloadPassagesHandler.ServeHTTP(w, r)
		default:
			http.NotFound(w, r)
		}
	})
}

// UnimplementedScrapeServiceHandler returns CodeUnimplemented from all methods.
type UnimplementedScrapeServiceHandler struct{}

func (UnimplementedScrapeServiceHandler) Scrape(context.Context, *connect.Request[v2.ScrapeRequest]) (*connect.Response[v2.ScrapeResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("mediawatch.scrape.v2.ScrapeService.Scrape is not implemented"))
}

func (UnimplementedScrapeServiceHandler) SimpleScrape(context.Context, *connect.Request[v2.SimpleScrapeRequest]) (*connect.Response[v2.ScrapeResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("mediawatch.scrape.v2.ScrapeService.SimpleScrape is not implemented"))
}

func (UnimplementedScrapeServiceHandler) ReloadPassages(context.Context, *connect.Request[v2.Empty]) (*connect.Response[v2.ReloadPassagesResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("mediawatch.scrape.v2.ScrapeService.ReloadPassages is not implemented"))
}
